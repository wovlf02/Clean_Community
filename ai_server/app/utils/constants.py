"""
상수 및 라벨 정의

9개 혐오 카테고리 라벨과 클래스별 최적화된 임계값을 정의합니다.
임계값은 ai-model/results/test_results.json에서 학습된 값을 사용합니다.
"""

# 9개 혐오 카테고리 라벨
LABELS = [
    "여성/가족",
    "남성",
    "성소수자",
    "인종/국적",
    "연령",
    "지역",
    "종교",
    "기타 혐오",
    "악플/욕설"
]

# 클래스별 최적화된 임계값
# UnSmile 테스트 결과 기반 최적화 (96.16% → 97%+ 목표)
THRESHOLDS = {
    "여성/가족": 0.35,  # 남성 혐오 문장에서 오탐 방지
    "남성": 0.22,
    "성소수자": 0.45,
    "인종/국적": 0.30,
    "연령": 0.30,       # 복합 문장에서 누락 방지
    "지역": 0.27,       # 복합 문장에서 누락 방지
    "종교": 0.30,
    "기타 혐오": 0.45,  # 0.60 → 0.45 (Recall 0.463 개선 - 정치 혐오 등 탐지 강화)
    "악플/욕설": 0.40   # 0.36 → 0.40 (Precision 0.678 개선 - 오탐 감소)
}

# 모델 가중치 (3-모델 앙상블: kcelectra + soongsil + roberta)
MODEL_WEIGHTS = {
    "kcelectra": 0.35,
    "soongsil": 0.33,
    "roberta": 0.32
}
