# 03. 모델 로딩

**관련 문서**: [모델 아키텍처](../../../ai-model/docs/03_모델_아키텍처.md) | [프로젝트 개요](../../../ai-model/docs/01_프로젝트_개요.md)

---

## 📋 개요

이 문서는 학습된 PyTorch 모델 파일(.pt)을 FastAPI 서버에 로드하고 앙상블 추론을 구성하는 방법을 설명합니다.

---

## ✅ 체크리스트

- [ ] MultiLabelClassifier 클래스 정의
- [ ] 모델 파일 로드 로직 구현
- [ ] 토크나이저 초기화
- [ ] 앙상블 래퍼 클래스 구현
- [ ] 가중 소프트 보팅 로직 구현
- [ ] 클래스별 임계값 적용 로직 구현
- [ ] 모델 로드 테스트

---

## 1. 모델 파일 정보

### 1.1 모델 파일 위치

| 모델 | 파일명 | 경로 | HuggingFace |
|------|--------|------|-------------|
| KcELECTRA | `kcelectra.pt` | `ai-model/models/kcelectra.pt` | beomi/KcELECTRA-base |
| SoongsilBERT | `soongsil.pt` | `ai-model/models/soongsil.pt` | soongsil-ai/soongsil-bert-base |
| RoBERTa-Base | `roberta_base.pt` | `ai-model/models/roberta_base.pt` | klue/roberta-base |

### 1.2 체크포인트 구조

각 `.pt` 파일은 다음 구조로 저장되어 있습니다:

```python
{
    'model_state_dict': model.state_dict(),  # 모델 가중치
    'model_name': 'kcelectra',               # 모델 이름
    'best_f1': 0.802,                        # 최고 F1 점수
    'epoch': 45,                             # 학습 에폭
    'threshold': 0.5                         # 기본 임계값
}
```

---

## 2. 분류기 클래스 구현

### 2.1 app/models/classifier.py

```python
import torch
import torch.nn as nn
from transformers import AutoModel

class MultiLabelClassifier(nn.Module):
    """
    다중 라벨 분류를 위한 BERT 기반 분류기
    
    참고: ai-model/docs/03_모델_아키텍처.md - 3. 분류기 헤드 설계
    """
    
    def __init__(
        self, 
        model_name: str, 
        num_labels: int = 9, 
        dropout_rate: float = 0.3
    ):
        super().__init__()
        
        # 1. 사전학습 모델 로드 (토크나이저용 모델명)
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size  # 768
        
        # 2. 분류기 헤드
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_size, num_labels)
        )
    
    def forward(
        self, 
        input_ids: torch.Tensor, 
        attention_mask: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            input_ids: 토큰 ID 텐서 [batch, seq_len]
            attention_mask: 어텐션 마스크 [batch, seq_len]
        
        Returns:
            logits: 분류 로짓 [batch, num_labels]
        """
        # [CLS] 토큰 임베딩 추출
        outputs = self.encoder(input_ids, attention_mask)
        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [batch, 768]
        
        # 분류 (Sigmoid는 추론 시 적용)
        logits = self.classifier(cls_embedding)  # [batch, 9]
        
        return logits
```

---

## 3. 모델 로더 구현

### 3.1 app/services/model_loader.py

```python
import os
import torch
from typing import Dict, Tuple, List
from transformers import AutoTokenizer

from app.models.classifier import MultiLabelClassifier
from app.config import settings
from app.utils.constants import LABELS

# 전역 변수로 로드된 모델 저장
_models: Dict[str, MultiLabelClassifier] = {}
_tokenizers: Dict[str, AutoTokenizer] = {}
_device: torch.device = None

def get_device() -> torch.device:
    """사용 가능한 디바이스 반환 (GPU 우선)"""
    global _device
    if _device is None:
        _device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    return _device

def load_single_model(
    model_name: str,
    checkpoint_path: str,
    hf_model_name: str
) -> Tuple[MultiLabelClassifier, AutoTokenizer]:
    """
    단일 모델과 토크나이저를 로드합니다.
    
    Args:
        model_name: 모델 식별자 (kcelectra, soongsil, roberta)
        checkpoint_path: .pt 파일 경로
        hf_model_name: HuggingFace 모델명 (토크나이저용)
    
    Returns:
        (model, tokenizer) 튜플
    """
    device = get_device()
    
    # 1. 모델 구조 생성
    model = MultiLabelClassifier(
        model_name=hf_model_name,
        num_labels=len(LABELS),
        dropout_rate=0.3
    )
    
    # 2. 체크포인트 로드
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # 3. 평가 모드 설정
    model.to(device)
    model.eval()
    
    # 4. 토크나이저 로드
    tokenizer = AutoTokenizer.from_pretrained(hf_model_name)
    
    print(f"✅ {model_name} 모델 로드 완료 (F1: {checkpoint.get('best_f1', 'N/A')})")
    
    return model, tokenizer

def load_models() -> None:
    """
    모든 앙상블 모델을 로드합니다.
    FastAPI lifespan에서 호출됩니다.
    """
    global _models, _tokenizers
    
    model_configs = [
        {
            'name': 'kcelectra',
            'checkpoint': os.path.join(settings.MODEL_PATH, 'kcelectra.pt'),
            'hf_model': settings.KCELECTRA_MODEL
        },
        {
            'name': 'soongsil',
            'checkpoint': os.path.join(settings.MODEL_PATH, 'soongsil.pt'),
            'hf_model': settings.SOONGSIL_MODEL
        },
        {
            'name': 'roberta',
            'checkpoint': os.path.join(settings.MODEL_PATH, 'roberta_base.pt'),
            'hf_model': settings.ROBERTA_MODEL
        }
    ]
    
    print(f"🔄 모델 로딩 시작 (Device: {get_device()})")
    
    for config in model_configs:
        model, tokenizer = load_single_model(
            model_name=config['name'],
            checkpoint_path=config['checkpoint'],
            hf_model_name=config['hf_model']
        )
        _models[config['name']] = model
        _tokenizers[config['name']] = tokenizer
    
    print(f"✅ 전체 모델 로드 완료 ({len(_models)}개)")

def get_models() -> Dict[str, MultiLabelClassifier]:
    """로드된 모델 딕셔너리 반환"""
    return _models

def get_tokenizers() -> Dict[str, AutoTokenizer]:
    """로드된 토크나이저 딕셔너리 반환"""
    return _tokenizers
```

---

## 4. 앙상블 래퍼 구현

### 4.1 app/models/ensemble.py

```python
import torch
import numpy as np
from typing import List, Dict

from app.services.model_loader import get_models, get_tokenizers, get_device
from app.config import settings
from app.utils.constants import LABELS, THRESHOLDS, MODEL_WEIGHTS

class EnsemblePredictor:
    """
    3-모델 하이브리드 앙상블 예측기
    
    참고: ai-model/docs/03_모델_아키텍처.md - 4. 앙상블 전략
    """
    
    def __init__(self):
        self.models = get_models()
        self.tokenizers = get_tokenizers()
        self.device = get_device()
        self.labels = LABELS
        self.thresholds = [THRESHOLDS[label] for label in LABELS]
        self.weights = MODEL_WEIGHTS
    
    def _tokenize(
        self, 
        text: str, 
        tokenizer
    ) -> Dict[str, torch.Tensor]:
        """텍스트를 토크나이징합니다."""
        inputs = tokenizer(
            text,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=settings.MAX_LENGTH
        )
        return {k: v.to(self.device) for k, v in inputs.items()}
    
    def _get_model_probs(
        self, 
        text: str, 
        model_name: str
    ) -> np.ndarray:
        """단일 모델의 확률 예측을 반환합니다."""
        model = self.models[model_name]
        tokenizer = self.tokenizers[model_name]
        
        inputs = self._tokenize(text, tokenizer)
        
        with torch.no_grad():
            logits = model(
                input_ids=inputs['input_ids'],
                attention_mask=inputs['attention_mask']
            )
            probs = torch.sigmoid(logits).cpu().numpy()[0]  # [9]
        
        return probs
    
    def predict(self, text: str) -> Dict:
        """
        가중 소프트 보팅을 통한 앙상블 예측
        
        Args:
            text: 분석할 텍스트
        
        Returns:
            {
                "text": "입력 텍스트",
                "labels": ["여성/가족", "악플/욕설"],
                "scores": {"여성/가족": 0.92, "악플/욕설": 0.85, ...},
                "is_toxic": True
            }
        """
        # 1. 각 모델별 확률 예측
        weighted_probs = np.zeros(len(self.labels))
        
        for model_name, weight in self.weights.items():
            probs = self._get_model_probs(text, model_name)
            weighted_probs += probs * weight
        
        # 2. 클래스별 임계값 적용
        detected_labels = []
        scores = {}
        
        for i, (label, prob, threshold) in enumerate(
            zip(self.labels, weighted_probs, self.thresholds)
        ):
            scores[label] = float(prob)
            if prob > threshold:
                detected_labels.append(label)
        
        # 3. 결과 반환
        return {
            "text": text,
            "labels": detected_labels,
            "scores": scores,
            "is_toxic": len(detected_labels) > 0
        }
    
    def predict_batch(self, texts: List[str]) -> List[Dict]:
        """
        배치 텍스트 예측
        
        Args:
            texts: 분석할 텍스트 리스트
        
        Returns:
            예측 결과 리스트
        """
        return [self.predict(text) for text in texts]

# 싱글톤 인스턴스
_predictor: EnsemblePredictor = None

def get_predictor() -> EnsemblePredictor:
    """앙상블 예측기 인스턴스 반환"""
    global _predictor
    if _predictor is None:
        _predictor = EnsemblePredictor()
    return _predictor
```

---

## 5. 추론 흐름

```
입력: "김치녀들은 진짜 답이 없다"
                │
                ▼
┌─────────────────────────────────────────────────────────────────┐
│                   각 모델별 토크나이징                           │
│   KcELECTRA Tokenizer → [CLS] 김 ##치 ##녀 ... [SEP]            │
│   Soongsil Tokenizer  → [CLS] 김치 ##녀 ... [SEP]               │
│   RoBERTa Tokenizer   → [CLS] 김치녀 ... [SEP]                  │
└─────────────────────────────────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────────────────────┐
│                   각 모델별 추론                                 │
│   KcELECTRA:    [0.91, 0.05, 0.02, 0.03, 0.01, 0.02, 0.01, 0.02, 0.82]
│   SoongsilBERT: [0.88, 0.04, 0.01, 0.02, 0.01, 0.01, 0.01, 0.03, 0.79]
│   RoBERTa:      [0.85, 0.03, 0.02, 0.02, 0.01, 0.02, 0.02, 0.01, 0.75]
└─────────────────────────────────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────────────────────┐
│                   가중 소프트 보팅                               │
│   가중치: KcELECTRA(0.35) + Soongsil(0.33) + RoBERTa(0.32)      │
│   결과:   [0.88, 0.04, 0.02, 0.02, 0.01, 0.02, 0.01, 0.02, 0.79]│
└─────────────────────────────────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────────────────────────────┐
│                   클래스별 임계값 적용                           │
│   여성/가족: 0.88 > 0.50 ✓                                      │
│   악플/욕설: 0.79 > 0.45 ✓                                      │
│   나머지:    임계값 미달 ✗                                       │
└─────────────────────────────────────────────────────────────────┘
                │
                ▼
출력: {
    "labels": ["여성/가족", "악플/욕설"],
    "scores": {...},
    "is_toxic": true
}
```

---

## 6. 모델 다운로드

학습된 모델 파일은 용량 문제로 GitHub에 포함되지 않습니다.

### 다운로드 방법

1. [Google Drive](https://drive.google.com/drive/folders/1Noow6HkhI6hkAuggptroiNmbUVGDbu1u?usp=sharing)에서 다운로드
2. `ai-model/models/` 폴더에 배치

```bash
ai-model/models/
├── kcelectra.pt      # KcELECTRA 가중치
├── soongsil.pt       # SoongsilBERT 가중치
└── roberta_base.pt   # RoBERTa-Base 가중치
```

---

## 🔗 참고 문서

| 문서 | 경로 | 설명 |
|------|------|------|
| 모델 아키텍처 | `ai-model/docs/03_모델_아키텍처.md` | 분류기 헤드, 앙상블 전략, 추론 파이프라인 |
| 프로젝트 개요 | `ai-model/docs/01_프로젝트_개요.md` | 모델 다운로드 링크, 프로젝트 구조 |
| 학습 전략 | `ai-model/docs/04_학습_전략.md` | 체크포인트 구조 |
| 실험 결과 | `ai-model/docs/05_실험_결과.md` | 모델별 성능 및 앙상블 효과 |

---

**이전 문서**: [02_환경_설정.md](./02_환경_설정.md)  
**다음 문서**: [04_API_엔드포인트.md](./04_API_엔드포인트.md)
