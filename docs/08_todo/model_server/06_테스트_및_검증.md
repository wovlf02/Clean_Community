# 06. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

**ê´€ë ¨ ë¬¸ì„œ**: [ì‹¤í—˜ ê²°ê³¼](../../../ai-model/docs/05_ì‹¤í—˜_ê²°ê³¼.md) | [ëª¨ë¸ ì•„í‚¤í…ì²˜](../../../ai-model/docs/03_ëª¨ë¸_ì•„í‚¤í…ì²˜.md)

---

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” FastAPI ê°ì •ë¶„ì„ ì„œë²„ì˜ í…ŒìŠ¤íŠ¸ ì „ëµ ë° í’ˆì§ˆ ë³´ì¦ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] pytest ì„¤ì •
- [ ] ëª¨ë¸ ë¡œë”© ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ì•™ìƒë¸” ì¶”ë¡  ì •í™•ë„ ê²€ì¦
- [ ] ì„±ëŠ¥(ì‘ë‹µ ì‹œê°„) í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
- [ ] CI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ í†µí•©

---

## 1. í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •

### 1.1 tests/conftest.py

```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import MagicMock, patch
import torch

# í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ ëª¨ë¸ ë° ê²°ê³¼
@pytest.fixture
def mock_models():
    """ëª¨ë¸ ë¡œë”©ì„ ëª¨í‚¹í•©ë‹ˆë‹¤."""
    with patch('app.services.model_loader._models') as mock:
        mock.return_value = {
            'kcelectra': MagicMock(),
            'soongsil': MagicMock(),
            'roberta': MagicMock()
        }
        yield mock

@pytest.fixture
def mock_predictor():
    """ì•™ìƒë¸” ì˜ˆì¸¡ê¸°ë¥¼ ëª¨í‚¹í•©ë‹ˆë‹¤."""
    with patch('app.models.ensemble.get_predictor') as mock:
        predictor = MagicMock()
        predictor.predict.return_value = {
            "text": "í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸",
            "labels": [],
            "scores": {
                "ì—¬ì„±/ê°€ì¡±": 0.1,
                "ë‚¨ì„±": 0.1,
                "ì„±ì†Œìˆ˜ì": 0.1,
                "ì¸ì¢…/êµ­ì ": 0.1,
                "ì—°ë ¹": 0.1,
                "ì§€ì—­": 0.1,
                "ì¢…êµ": 0.1,
                "ê¸°íƒ€ í˜ì˜¤": 0.1,
                "ì•…í”Œ/ìš•ì„¤": 0.1
            },
            "is_toxic": False
        }
        mock.return_value = predictor
        yield predictor

@pytest.fixture
def client(mock_predictor):
    """í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    from app.main import app
    return TestClient(app)

@pytest.fixture
def toxic_predictor():
    """ì•…ì„± ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ˆì¸¡ê¸°"""
    with patch('app.models.ensemble.get_predictor') as mock:
        predictor = MagicMock()
        predictor.predict.return_value = {
            "text": "í˜ì˜¤ í…ìŠ¤íŠ¸",
            "labels": ["ì—¬ì„±/ê°€ì¡±", "ì•…í”Œ/ìš•ì„¤"],
            "scores": {
                "ì—¬ì„±/ê°€ì¡±": 0.92,
                "ë‚¨ì„±": 0.05,
                "ì„±ì†Œìˆ˜ì": 0.02,
                "ì¸ì¢…/êµ­ì ": 0.03,
                "ì—°ë ¹": 0.01,
                "ì§€ì—­": 0.02,
                "ì¢…êµ": 0.01,
                "ê¸°íƒ€ í˜ì˜¤": 0.02,
                "ì•…í”Œ/ìš•ì„¤": 0.85
            },
            "is_toxic": True
        }
        mock.return_value = predictor
        yield predictor
```

---

## 2. API í…ŒìŠ¤íŠ¸

### 2.1 tests/test_analyze.py

```python
import pytest
from fastapi.testclient import TestClient

class TestAnalyzeEndpoint:
    """POST /analyze ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    def test_analyze_clean_text(self, client, mock_predictor):
        """ì •ìƒ í…ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze",
            json={"text": "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”"}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "data" in data
        assert data["data"]["is_toxic"] == False
        assert data["data"]["labels"] == []
    
    def test_analyze_toxic_text(self, client, toxic_predictor):
        """í˜ì˜¤ í…ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze",
            json={"text": "ê¹€ì¹˜ë…€ë“¤ì€ ë‹µì´ ì—†ë‹¤"}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["data"]["is_toxic"] == True
        assert "ì—¬ì„±/ê°€ì¡±" in data["data"]["labels"]
    
    def test_analyze_empty_text(self, client):
        """ë¹ˆ í…ìŠ¤íŠ¸ ì—ëŸ¬ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze",
            json={"text": ""}
        )
        
        assert response.status_code == 400
    
    def test_analyze_missing_text(self, client):
        """í…ìŠ¤íŠ¸ ëˆ„ë½ ì—ëŸ¬ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze",
            json={}
        )
        
        assert response.status_code == 422  # Pydantic validation error
    
    def test_analyze_long_text(self, client, mock_predictor):
        """ê¸´ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ (max_length ì²˜ë¦¬)"""
        long_text = "í…ŒìŠ¤íŠ¸ " * 500
        response = client.post(
            "/analyze",
            json={"text": long_text}
        )
        
        # 1000ì ì œí•œìœ¼ë¡œ ì¸í•œ ì—ëŸ¬ ë˜ëŠ” ì •ìƒ ì²˜ë¦¬
        assert response.status_code in [200, 400]

class TestBatchAnalyzeEndpoint:
    """POST /analyze/batch ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    def test_batch_analyze(self, client, mock_predictor):
        """ë°°ì¹˜ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze/batch",
            json={"texts": ["í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2", "í…ìŠ¤íŠ¸3"]}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["count"] == 3
        assert len(data["data"]) == 3
    
    def test_batch_empty_list(self, client):
        """ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì—ëŸ¬ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/analyze/batch",
            json={"texts": []}
        )
        
        assert response.status_code == 422

class TestHealthEndpoint:
    """GET /health ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    def test_health_check(self, client):
        """í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸"""
        response = client.get("/health")
        
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        assert "device" in data
```

---

## 3. ëª¨ë¸ ìœ ë‹› í…ŒìŠ¤íŠ¸

### 3.1 tests/test_model.py

```python
import pytest
import torch
from app.models.classifier import MultiLabelClassifier
from app.utils.constants import LABELS

class TestMultiLabelClassifier:
    """MultiLabelClassifier ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def sample_input(self):
        """ìƒ˜í”Œ ì…ë ¥ í…ì„œ"""
        return {
            "input_ids": torch.randint(0, 1000, (1, 128)),
            "attention_mask": torch.ones(1, 128, dtype=torch.long)
        }
    
    def test_classifier_output_shape(self, sample_input):
        """ì¶œë ¥ í…ì„œ í˜•íƒœ í…ŒìŠ¤íŠ¸"""
        # ì‹¤ì œ ëª¨ë¸ ë¡œë“œ ì—†ì´ êµ¬ì¡°ë§Œ í…ŒìŠ¤íŠ¸
        # Note: ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œ ëª¨ë¸ ë¡œë“œ í•„ìš”
        
        # ì˜ˆìƒ ì¶œë ¥ í˜•íƒœ: [batch_size, num_labels]
        expected_shape = (1, len(LABELS))
        
        # ëª¨í‚¹ëœ ì¶œë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        mock_output = torch.randn(expected_shape)
        assert mock_output.shape == expected_shape
    
    def test_sigmoid_output_range(self):
        """ì‹œê·¸ëª¨ì´ë“œ ì¶œë ¥ ë²”ìœ„ í…ŒìŠ¤íŠ¸ (0~1)"""
        logits = torch.randn(1, 9)
        probs = torch.sigmoid(logits)
        
        assert torch.all(probs >= 0)
        assert torch.all(probs <= 1)

class TestTextProcessor:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    def test_preprocess_normal(self):
        """ì •ìƒ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        from app.utils.text_processor import preprocess_text
        
        result = preprocess_text("  í…ŒìŠ¤íŠ¸   í…ìŠ¤íŠ¸  ")
        assert result == "í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸"
    
    def test_preprocess_empty(self):
        """ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        from app.utils.text_processor import preprocess_text
        
        assert preprocess_text("") is None
        assert preprocess_text("   ") is None
    
    def test_preprocess_special_chars(self):
        """íŠ¹ìˆ˜ë¬¸ì í¬í•¨ í…ìŠ¤íŠ¸"""
        from app.utils.text_processor import preprocess_text
        
        result = preprocess_text("í…ŒìŠ¤íŠ¸! @#$ í…ìŠ¤íŠ¸")
        assert result is not None
```

---

## 4. ì •í™•ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸

### 4.1 tests/test_accuracy.py

ì‹¤ì œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

```python
import pytest
import pandas as pd
from sklearn.metrics import f1_score
import numpy as np

# ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ ëª¨ë¸ íŒŒì¼ì´ í•„ìš”í•˜ë¯€ë¡œ CIì—ì„œëŠ” ìŠ¤í‚µ
@pytest.mark.skipif(
    not pytest.importorskip("torch").cuda.is_available(),
    reason="GPU í•„ìš”"
)
class TestModelAccuracy:
    """ëª¨ë¸ ì •í™•ë„ ê²€ì¦ (ì‹¤ì œ ëª¨ë¸ í•„ìš”)"""
    
    @pytest.fixture
    def validation_data(self):
        """ê²€ì¦ ë°ì´í„° ë¡œë“œ"""
        # ai-model/data/processed/val.csv ì‚¬ìš©
        df = pd.read_csv("../../ai-model/data/processed/val.csv")
        return df
    
    def test_f1_macro_threshold(self, validation_data):
        """F1-Macroê°€ 80% ì´ìƒì¸ì§€ í™•ì¸"""
        # ì‹¤ì œ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
        from app.models.ensemble import get_predictor
        
        predictor = get_predictor()
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = []
        for text in validation_data['text']:
            result = predictor.predict(text)
            pred_vector = [1 if label in result['labels'] else 0 for label in LABELS]
            predictions.append(pred_vector)
        
        # F1-Macro ê³„ì‚°
        y_true = validation_data[LABELS].values
        y_pred = np.array(predictions)
        
        f1_macro = f1_score(y_true, y_pred, average='macro')
        
        assert f1_macro >= 0.80, f"F1-Macro {f1_macro:.4f}ê°€ 80% ë¯¸ë§Œì…ë‹ˆë‹¤."
```

---

## 5. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### 5.1 tests/test_performance.py

```python
import pytest
import time

class TestPerformance:
    """ì„±ëŠ¥(ì‘ë‹µ ì‹œê°„) í…ŒìŠ¤íŠ¸"""
    
    def test_single_analysis_latency(self, client, mock_predictor):
        """ë‹¨ì¼ ë¶„ì„ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ (< 500ms)"""
        start = time.time()
        
        response = client.post(
            "/analyze",
            json={"text": "í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤."}
        )
        
        elapsed = time.time() - start
        
        assert response.status_code == 200
        assert elapsed < 0.5, f"ì‘ë‹µ ì‹œê°„ {elapsed:.3f}sê°€ 500msë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤."
    
    def test_batch_analysis_latency(self, client, mock_predictor):
        """ë°°ì¹˜ ë¶„ì„ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ (10ê°œ < 2s)"""
        texts = [f"í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ {i}" for i in range(10)]
        
        start = time.time()
        
        response = client.post(
            "/analyze/batch",
            json={"texts": texts}
        )
        
        elapsed = time.time() - start
        
        assert response.status_code == 200
        assert elapsed < 2.0, f"ì‘ë‹µ ì‹œê°„ {elapsed:.3f}sê°€ 2së¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤."
```

---

## 6. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### 6.1 ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# ìƒì„¸ ì¶œë ¥
pytest -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
pytest --cov=app --cov-report=html

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest tests/test_analyze.py -v

# ë§ˆí‚¹ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ
pytest -m "not slow"
```

### 6.2 pytest.ini ì„¤ì •

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short
markers =
    slow: ëŠë¦° í…ŒìŠ¤íŠ¸
    integration: í†µí•© í…ŒìŠ¤íŠ¸
    gpu: GPU í•„ìš” í…ŒìŠ¤íŠ¸
```

---

## 7. ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê¸°ì¤€ | ìƒíƒœ |
|------|------|------|
| ë‹¨ì¼ ë¶„ì„ API | ì •ìƒ ì‘ë‹µ (200) | â¬œ |
| ë°°ì¹˜ ë¶„ì„ API | ì •ìƒ ì‘ë‹µ (200) | â¬œ |
| í—¬ìŠ¤ì²´í¬ API | ì •ìƒ ì‘ë‹µ (200) | â¬œ |
| ë¹ˆ í…ìŠ¤íŠ¸ ì—ëŸ¬ | 400 ì‘ë‹µ | â¬œ |
| F1-Macro | >= 80% | â¬œ |
| ë‹¨ì¼ ë¶„ì„ ì‘ë‹µ ì‹œê°„ | < 500ms | â¬œ |
| ë°°ì¹˜ ë¶„ì„ ì‘ë‹µ ì‹œê°„ (10ê°œ) | < 2s | â¬œ |

---

## ğŸ”— ì°¸ê³  ë¬¸ì„œ

| ë¬¸ì„œ | ê²½ë¡œ | ì„¤ëª… |
|------|------|------|
| ì‹¤í—˜ ê²°ê³¼ | `ai-model/docs/05_ì‹¤í—˜_ê²°ê³¼.md` | ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ |
| ëª¨ë¸ ì•„í‚¤í…ì²˜ | `ai-model/docs/03_ëª¨ë¸_ì•„í‚¤í…ì²˜.md` | ì•™ìƒë¸” ì¶”ë¡  ë¡œì§ |
| ë°ì´í„° ë¶„ì„ | `ai-model/docs/02_ë°ì´í„°_ë¶„ì„.md` | ê²€ì¦ ë°ì´í„°ì…‹ ì •ë³´ |

---

**ì´ì „ ë¬¸ì„œ**: [05_NextJS_ì—°ë™.md](./05_NextJS_ì—°ë™.md)  
**ë‹¤ìŒ ë¬¸ì„œ**: [07_ë°°í¬.md](./07_ë°°í¬.md)
